{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Ilastik object classifiers with SpatialData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Environment: harpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Automatically reload imported packages\n",
    "# (This makes it easy to quickly test changes to our own code\n",
    "# external to this notebook without restarting the kernel.)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spatialdata as sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\julienm\\Documents\\repos_github\\ilastik_spatialdata\")\n",
    "import sdata_to_ilastik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpatialData object, with associated Zarr store: D:\\Data\\Ilastik test\\sdata.zarr\n",
       "├── Images\n",
       "│     └── 'raw_image': SpatialImage[cyx] (2, 6935, 6706)\n",
       "├── Labels\n",
       "│     └── 'segmentation_mask': SpatialImage[yx] (6935, 6706)\n",
       "└── Tables\n",
       "      ├── 'table': AnnData (29, 2)\n",
       "      └── 'table_intensities': AnnData (29, 2)\n",
       "with coordinate systems:\n",
       "    ▸ 'global', with elements:\n",
       "        raw_image (Images), segmentation_mask (Labels)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdata = sd.read_zarr(r\"d:\\Data\\Ilastik test\\sdata.zarr\")\n",
    "sdata\n",
    "\n",
    "# NOTE: The SpatialData object needs to contain the image channels and a corresponding segmentation mask. \n",
    "# To add the results of Ilastik back to the SpatialData object, it needs to contain a table with the centroid coordinates calculated per cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a variety of diffent object classifiers that can be created in ilastik.\n",
    "\n",
    "Some options:\n",
    "- You can train on a single image or on a combination of images\n",
    "- You can train on any set of features that is most appropriate\n",
    "- You can have as many classes as is needed\n",
    "- You can classify for anything as long as you can visually recognize it yourself on an image (or a set of images)\n",
    "\n",
    "For example:\n",
    "- You can use the DAPI channel to classify cells in good segmentations and bad segmentations.\n",
    "- You can train for each channel a classifier that classifies cells in positive and negative for that marker.\n",
    "- You can train on multiple channels (e.g. CD45 and Sox10) simultaneously to, for example, classify cells in tumor, immune and other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save raw images and corresponding segmentation mask for training ilastik object classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata_to_ilastik.export_h5(\n",
    "    sdata = sdata,\n",
    "    img_layer = \"raw_image\",\n",
    "    channels = [\"CD11b\", \"Ly6G\"],\n",
    "    output = \"D:/Data/Ilastik test/raw_images.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata_to_ilastik.export_h5(\n",
    "    sdata = sdata,\n",
    "    labels_layer = \"segmentation_mask\",\n",
    "    output = \"D:/Data/Ilastik test/segmentation_mask.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Object classifiers in Ilastik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each object classifier, do the following:\n",
    "\n",
    "Open Ilastik (v.1.4.0) and create an new project: Object Classification [Inputs: Raw Data, Segmentation]\n",
    "\n",
    "**1. Input Data** </br>\n",
    "To load in a separate channel, you need to do the following:\n",
    "\n",
    "- Under the tab `Raw Data` from `1. Input Data`, you would click `Add...` and select `Add separate Image(s)...`.\n",
    "- Select the .h5 file (which contains the raw images) and you will need to specify which channel you want to work on from the drop-down menu and click `OK` (this specifies the internal path in the h5 file).\n",
    "\n",
    "To load in multiple channels, you need to specify a correct pattern that also includes the internal path (i.e. in the h5 file) to the correct images.\n",
    "\n",
    "For example:\n",
    "- Under the tab 'Raw Data' from '1. Input Data', you would click 'Add...' and select 'Add a single 3D/4D Volume from Sequence...'.\n",
    "- Under `Specify Pattern`, you enter a patterns that specifies the images of interest. For example: `D:/Data/2023-09-ChristosGkemisis-ChMa/processed/CG23-003_4/CG23-003_4_Scan2/tissue4/annotation/ilastik/tissue4.h5/CD45; D:/Data/2023-09-ChristosGkemisis-ChMa/processed/CG23-003_4/CG23-003_4_Scan2/tissue4/annotation/ilastik/tissue4.h5/Sox10` and click `Apply`. It is important that the path is specified correctly, multiple paths should be separated by a semicolon and the internal path in the h5 file should be specified as well in the path.\n",
    "- Select `Stack Across: C` before clicking `OK`.\n",
    "\n",
    "After adding the Raw Data and the Segmentation Image to the ilastik project, it is useful to right-click on them, go to `Edit properties...` and make sure `Storage:` is set to `Copy into project file`. This makes sure, you can move around the ilastik project file (on your computer or even to other computers) without losing the link to the files the project was trained on (and risk losing your training). It is also useful to set `Nickname:` to something informative such as the name of the tissue/sample/replicate/etc (to keep track of which image is which).\n",
    "\n",
    "**2. Object Feature Selection** </br>\n",
    "To select features for training, it would be recommended to not select all of them, but be mindful of which you want to train on. Although ilastik itself describes computing many features at once as computationally cheap, it can still really add up to calculate all features since there are a lot of cells in each image. Additionally, by, for example, only working on intensity-related features, it becomes more explanable what the model was trained on how it can be interpreted.\n",
    "\n",
    "For most cases, I would recommend to follow these steps:\n",
    "- Under the tab `2. Object Feature Selection`, click `Select Features` and click all boxes under `Intensity Distribution`. You can add other features that you know are relevant, if needed (such as `Size in pixels` or `Diameter`). In case you want create a classifier to distinguish good segmentations from bad segmentation, it would make sense to select all features.\n",
    "- After clicking `OK`, wait until all features have been computed before moving on to the next step.\n",
    "\n",
    "**3. Object Classification** </br>\n",
    "Here, you can create multiple classes for your classifier and train them until you are satisfied with the results. In general, it is useful to initially add a good amount of labels for the different classes for different regions of the image (or even already over multiple images) to capture the variation that is in the data and click `Live Update` to see the prediction results. Subsequently, you can focus more on the mistakes that are being made and add labels to correct those. When labeling, I prefer to unclick `Live Update` to avoid waiting time. It can be useful to use the `Uncertainty` layer to see which objects are still not robustly trained for. When training, ilastik does not make it easy to change the visualization, but if you right-click on `Raw Input` and select `Adjust Thresholds`, you have some options to change the display.\n",
    "\n",
    "**4. Object Information Export** </br>\n",
    "To export the results, click on `Configure Feature Table Export` and export as either `HDF (.h5)` or`CSV (.csv)`. \n",
    "\n",
    "Under `Choose File`, you can specify where and under what name you want to export the results. By default, this is set to `{dataset_dir}/{nickname}.csv`, with `{dataset_dir}` refering to the directory the input images .h5 file is in and `{nickname}` refering to the name specified in the `1. Input Data` tab. Preferably, remove `{nickname}` and put a unique name in its place for each ilastik classifier. This is important since it will allow you to keep track of which object classifier the results come from when adding everything together in SpatialData.\n",
    "\n",
    "Note that, by default, the object predictions will be saved as images as well, while these files will not be used to add the ilastik results to the SpatialData. Unfortunately, there does not seem to be a way to avoid saving these files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load in ilastik output and add to sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 10:23:27,549 - sparrow.utils._io - WARNING - layer with name 'table' already exists. Overwriting...\n"
     ]
    }
   ],
   "source": [
    "sdata = sdata_to_ilastik.add_ilastik_to_sdata(\n",
    "    sdata = sdata,\n",
    "    input_path = r\"d:\\Data\\Ilastik test\\raw_images-CD11b.h5\",\n",
    "    table_layer = \"table\",\n",
    "    labels_layer = \"segmentation_mask\",\n",
    "    centroid_column_x = \"centroid-1\",\n",
    "    centroid_column_y = \"centroid-0\", \n",
    "    suffix = \"test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating new ilastik columns based on specified conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 10:23:30,252 - sparrow.utils._io - WARNING - layer with name 'table' already exists. Overwriting...\n",
      "2024-06-12 10:23:31,183 - sparrow.utils._io - WARNING - layer with name 'table' already exists. Overwriting...\n"
     ]
    }
   ],
   "source": [
    "sdata = sdata_to_ilastik.assign_ilastik_cell_types(\n",
    "    sdata, \n",
    "    table_layer = \"table\",\n",
    "    labels_layer = \"segmentation_mask\",\n",
    "    annotation_table_path = r\"d:\\Data\\Ilastik test\\annotation_matrix.csv\",\n",
    "    output_column = \"ilastik_cell_types\", \n",
    "    default_value = \"other\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mesmer_sparrow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
